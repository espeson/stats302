{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 -  Classification and Neural Networks\n",
    "\n",
    "## *YOUR FULL NAME HERE*\n",
    "Netid:  *Your netid here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Mathematical description of NN\n",
    "\n",
    "### (2.5 points)\n",
    "\n",
    "Let's assume you have a deep neural network with 10 input neurons, one hidden layer with 50 neurons, and one output layer with 3 neurons. All neurons use the hyperbolic tangent as activation. \n",
    "\n",
    "**(a)** What are the dimensions of a pair of feature and target variables $\\bf x_i$  and $\\bf y_i$? (*0.5 points*)\n",
    "\n",
    "**(b)** What are the dimensions of the first weight matrix $\\bf w_1$ and the corresponding bias vector $\\bf b_1$?  (*0.5 points*)  \n",
    "\n",
    "**(c)** What are the dimensions of the weight matrix $\\bf w_2$ and the bias vector $\\bf b_2$ of the output layer?   (*0.5 points*)\n",
    "\n",
    "**(d)** Write down the equation to compute $\\bf y_i$. (*0.5 points*)\n",
    "\n",
    "**(e)** How many trainable parameters does this network have? (*0.5 points*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Classification with a deep neural network \n",
    "### (4 points)\n",
    "\n",
    "**(a)** Create 1000 training and 400 test data points with the make_moons function from Scikit Learn. Set the noise level to 0.2. (*0.5 points*)\n",
    "\n",
    "**(b)**  Design a neural network using Keras. The first hidden layer has 100 neurons with rectified linear units as activation. The second hidden layer has 25 neurons and also rectified linear units as activation. The output layer uses \n",
    "sigmoid activation. The loss function is binary crossentropy, the gradient descent method is Adam and the metric used for evaluation is accuracy. (*1 point*)\n",
    "\n",
    "**(c)** Train the network with a batch size of 64 for 100 epochs. Use early stopping if the validation loss does not change over 4 epochs. Report the test accuracy. (*0.5 point*)\n",
    "\n",
    "**(d)** Plot the test data points together with a mesh indicating the prediction of the neural network. (You can reuse the code from the logistic regression examle.)  (*0.5 point*)\n",
    "\n",
    "**(e)** Make two figures showing the evolution of loss and accuracy as a function of number of epochs. In both figures show training and test results.(*0.5 point*)\n",
    "\n",
    "**(f)** Create a new model where you change the the activation of the two hidden layers to sigmoid. Train it and plot the prediction together with the test data (as in part d) (*1 point*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Precision or recall\n",
    "### (1 point)\n",
    "\n",
    "Invent a new (i.e. not yet exisiting) machine learning classifier, one that you would like to use in **your personal** daily life. Would you rather want a high precision, recall, or do they matter both? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Demonstration of the universal approximation theorem\n",
    "### (4.5 points)\n",
    "\n",
    "\n",
    "**(a)**  Write a function which computes $f(x)=0.2 + 0.4 \\;x^2 + 0.3 \\;x\\; sin(9x)$. Create a vector x_train which contains 10000 evenly spaced points between 0 and 1. Compute the vector y_train = f(x_train). Plot y_train versus x_train. This is the function we want to approximate with a neural network containing one hidden layer. (*1 point*)\n",
    "\n",
    "**(b)**  Create a neural network with one input neuron, a hidden layer with 50 neurons and sigmoid activation and one output neuron with linear activation. Choose Mean Squared Error as loss function and Adam(learning_rate=0.005) as gradient descent method. Train the model with a batch size of 2000 for 4000 epochs. (We do not need test data in this demonstration.)\n",
    "\n",
    "After training the network make a prediction using x_train and plot this prediction together with y_train (i.e. the function the network tries to approximate). (*2 points*)\n",
    "\n",
    "**(c)**  Plot the evolution of the loss function with a logarithmic y-axis. Then re-initialize the network (!) and rerun the training with the learning rate for Adam set to 0.002. Plot again the evolution of the loss function-\n",
    "Describe in one sentence how this curve has changed.  \n",
    "(*1.5 points*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
